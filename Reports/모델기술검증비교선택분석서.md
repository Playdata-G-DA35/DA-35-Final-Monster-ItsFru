# Instance Segmentation 기술 검증 비교 선택 분석서

## 1. 개요

본 프로젝트에서는 인스턴스 세그멘테이션(Instance Segmentation)기술을 활용해 과일의 품목을 분류하고, 객체의 마스크를 추출해 이상 부분을 탐지하고자 한다. 따라서 높은 정확도와 빠른 추론 속도로 객체를 탐지하고 마스크를 추출하는 Instance Segmentation 모델을 선택하고, custom dataset으로 파인튜닝하여 과일 종류를 구분 segmentation 모델을 만들고자 한다. 

## 2. 사용 기술 

Segmentation은 영상에서 객체를 식별하고, 픽셀단위로 특정 클래스에 할당하여 객체의 정확한 형태를 식별하는 기술이다. 시맨틱 세그멘테이션(Semantic Segmentation)은 같은 클래스의 다른 객체를 구분하지 않지만, 인스턴스 세그멘테이션(Instance Segmentation)은 같은 클래스에서도 서로 다른 객체를 구분하는 것이 특징이다. 본 모델을 활용할 무인 과일 매장에서는 정확한 결제를 위해 각 과일의 개별적인 인식과 정확한 수량 파악이 필요하므로 인스턴스 세그멘테이션 모델이 적합하다. 

## 3. 모델 비교 및 선정

### 3.1. COCO Benchmark 결과 비교 

MS COCO 데이터셋은 객체 탐지와 세그멘테이션 모델의 성능을 평가하는 데 사용되는 대표적인 데이터셋이다. 세그멘테이션 모델은 객체탐지 모델을 기반으로 하므로, 객체 탐지 모델과 함께 COCO 벤치마크 결과를 비교하여 모델의 전반적인 성능을 파악하고 적합한 인스턴스 세그멘테이션 모델을 선택하고자 하였다. 


| Model         | mAP (0.5:0.95) | mAP@0.5 | mAP@0.75 | Params (M) | FPS (on GPU) | Year | Reference                       |
|---------------|----------------|---------|----------|------------|--------------|------|---------------------------------|
| Faster R-CNN  | 37.4           | 58.4    | 39.4     | 41         | ~6-7         | 2015 | 논문: [Faster R-CNN](https://arxiv.org/abs/1506.01497) |
| Mask R-CNN    | 38.2           | 60.3    | 40.6     | 44         | ~5           | 2017 | 논문: [Mask R-CNN](https://arxiv.org/abs/1703.06870)   |
| SSD           | 25.1           | 43.1    | 25.8     | 34         | ~46          | 2016 | 논문: [SSD](https://arxiv.org/abs/1512.02325)          |
| YOLOv5        | 50.4           | 69.7    | 55.2     | 7.1        | ~140         | 2020 | GitHub: [YOLOv5 GitHub](https://github.com/ultralytics/yolov5) |
| YOLOv8        | 52.3           | 70.6    | 56.3     | 11.2       | ~150         | 2023 | GitHub: [YOLOv8 GitHub](https://github.com/ultralytics/yolov8) |

> **성능 평가 지표**
> - mAP (0.5:0.95): IoU 0.5에서 0.95까지를 기준으로 한 평균 정확도
>   - IoU(Intersection over Union) : 객체탐지 모델이 예측한 bbox와 실제 bbox 간의 일치도 측정 지표
> - mAP@0.5: IoU 0.5에서의 평균 정확도
>- mAP@0.75:  IoU  0.75에서의 평균 정확도
>- Params (M):  모델의 파라미터 수(백만 단위), 모델의 복잡도와 메모리 요구 사항 의미
> - FPS (on GPU): GPU에서의 초당 프레임 수

### 3.2. Instance Segmentation 모델 비교 
#### -  YOLOv8-seg vs. Mask R-CNN

COCO 벤치마크 모델 중 세그멘테이션 모델인 YOLOv8-seg와 Mask R-CNN 모델을 다양한 기준으로 비교하였다. YOLOv8-seg는 단일 스테이지 접근 방식으로 객체탐지와 세그멘테이션이 동시에 이루어져 처리 속도가 빠르고 실시간 성능에 강점을 가진다. 반면 Mask R-CNN은 두 스테이지 접근 방식을 사용하며, 첫 번째 스테이지에서 Region Proposal을 생성하고, 두 번째 스테이지에서는 제안된 영역에서 객체 분류 및 마스크를 예측해 정확도가 높고 세부적인 객체 처리에 유리하다. 본 프로젝트에서는 고객이 촬영한 사진에 대해 실시간 추론이 이루어질 수 있도록 YOLOv8-seg모델을 선택했다.

| **비교 항목**                | **YOLOv8-seg**                              | **Mask R-CNN**                        |
|-----------------------------|---------------------------------------------|---------------------------------------|
| **기반 아키텍처**            | YOLO (You Only Look Once)                   | Faster R-CNN (Region Proposal 기반)   |
| **접근 방식**                | 단일 스테이지 접근                          | 두 스테이지 접근                      |
| **세그멘테이션 방식**        | Bounding Box와 마스크 예측을 동시에 수행    | Region Proposal 후 마스크 예측        |
| **학습 속도**                | 빠름                                       | 느림                                 |
| **추론 속도**                | 실시간 성능 가능                           | 상대적으로 느림                       |
| **모델 복잡도**              | 상대적으로 단순함                          | 상대적으로 복잡함                     |
| **메모리 사용량**            | 낮음                                       | 높음                                 |
| **성능 (COCO mAP)**          | 중간 (정확도는 다소 낮음)                  | 높음 (정확도가 우수함)               |
| **처리 가능한 객체 크기**    | 주로 큰 객체에 유리                        | 작은 객체도 잘 처리 가능              |


## 4. YOLO 프레임워크 특징 

1. 객체 탐지 작업을 단일 네트워크(CNN)에서 처리하여 처리 속도가 빠르고, 실시간 추론이 가능
2. 예측된 객체의 마스크, 바운딩 박스, 클래스 확률을 출력하여 간단한 후처리 가능
3. 다양한 버전(Object Detection, Segmentation, Pose)과 사이즈(n, s, m, l, x)의 모델을 제공해 확장 가능성이 높음

### 4.2. YOLOv8-segmentation 모델

- YOLOv8 모델의 사이즈별 COCO 벤치마크 결과
  
| MODEL       | SIZE | mAPbox 50-95 | mAPmask 50-95 | Speed CPU ONNX (ms) | Speed A100 TensorRT (ms) | Params (M) | FLOPs (B) |
|-------------|------|--------------|---------------|----------------------|---------------------------|------------|-----------|
| YOLOv8n-seg | 640  | 36.7         | 30.5          | 96.1                 | 1.21                      | 3.4        | 12.6      |
| YOLOv8s-seg | 640  | 44.6         | 36.8          | 155.7                | 1.47                      | 11.8       | 42.6      |
| YOLOv8m-seg | 640  | 49.9         | 40.8          | 317.0                | 2.18                      | 27.3       | 110.2     |
| YOLOv8l-seg | 640  | 52.3         | 42.6          | 572.4                | 2.79                      | 46.0       | 220.5     |
| YOLOv8x-seg | 640  | 53.4         | 43.4          | 712.1                | 4.02                      | 71.8       | 344.1     |

> **성능 평가 지표** 
> - mAPbox : 객체 탐지 평균 정밀도(mAP)
> - mAPmask : 세그멘테이션 평균 정밀도(mAP)
> - Speed CPU ONNX(ms) : CPU에서 onnx형식으로 모델 실행시 속도
> - Speed A100 TensorRT(ms) : NVIDIA A100 GPU에서 TensorRT로 모델을 실행할 때의 속도
> - Params (M) : 모델의 총 파라미터 수, 모델의 복잡성 및 용량 측정
> - FLOPs (B) : 모델이 처리하는 부동 소수점 연산 수

### 5. 파인튜닝 계획
1. 데이터 
   - AIHUB 농산물 QC 농산물 품질 데이터셋

2. 활용 모델
   - 하이퍼파라미터 튜닝 시 YOLOv8n-seg을 활용
   - 최적의 하이퍼파라미터 조합으로 초기 설정 후 YOLOv8m-seg 모델로 최종 학습

3. 학습 환경 
   - Google COLAB
   - GPU 
     - 1차 파인튜닝 : NVIDIA T4
     - 2차 파인튜닝 : NVIDIA A100
   
