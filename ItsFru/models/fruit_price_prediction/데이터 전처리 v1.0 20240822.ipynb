{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2f6d72e-9a90-44ee-9520-90848903189a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\price\\env\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\price\\env\\lib\\site-packages (from pandas) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\price\\env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\price\\env\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\price\\env\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\price\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "534f17a4-82be-4487-a678-d1470df2aaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d55f9af0-91d3-4baa-a9e4-53b83a693d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\price\\env\\lib\\site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7f85a37-afbe-47c8-bea4-ed24d00b7e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\price\\env\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\price\\env\\lib\\site-packages (from scikit-learn) (2.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\price\\env\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\price\\env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\price\\env\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48706425-9f00-44b9-8d12-273b6e7aa69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5440dae4-fab2-4464-9fc2-9ebd678b9e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엑셀 파일 경로와 CSV 파일 저장 경로 설정\n",
    "excel_file = 'test/가락시장 반입량 20240802-20240820.xlsx'  # 변환하려는 엑셀 파일의 경로\n",
    "csv_file = 'test/가락시장 반입량 20240802-20240820.csv'   # 저장할 CSV 파일의 경로\n",
    "\n",
    "# 엑셀 파일 읽기\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# CSV 파일로 저장하기\n",
    "df.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2134d31f-28c7-4f43-afa0-fcc2dca866e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv('test/기후데이터 20240802-20240820_UTF8.csv')\n",
    "\n",
    "# 행 순서 뒤집기 (과거순)\n",
    "df_reversed = df.iloc[::-1]\n",
    "\n",
    "# 결과를 새로운 CSV 파일로 저장\n",
    "df_reversed.to_csv('test/기후데이터 20240802-20240820_UTF8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4091bc9c-191d-4c28-ad36-062ad2b22eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기후데이터 인코딩\n",
    "input_file = 'test/기후데이터 20240802-20240820.csv'\n",
    "output_file = 'test/기후데이터 20240802-20240820_UTF8.csv'\n",
    "\n",
    "with open(input_file, 'r', encoding='cp949') as f:\n",
    "    with open(output_file, 'w', encoding='utf-8') as out_f:\n",
    "        out_f.write(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e14949cd-4b9b-48ca-8b2a-aff0b740ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv('test/기후데이터 20240802-20240820_UTF8.csv')\n",
    "\n",
    "# 날짜 형식 변환\n",
    "df['조회일자'] = pd.to_datetime(df['조회일자'].astype(str), format='%Y%m%d')\n",
    "\n",
    "# 변환된 데이터 저장\n",
    "df.to_csv('test/기후데이터 20240802-20240820_UTF8_날짜형식변환.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ad45849-edcb-4b03-9246-169b03098599",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          DATE  품목  품종 거래단위  등급          평균가격               전일_x 전년_x  \\\n",
      "0   2024-08-02  사과  후지  10개  상품  30535.416667  30133.33333333333    -   \n",
      "1   2024-08-05  사과  후지  10개  상품  30173.913043                  -    -   \n",
      "2   2024-08-06  사과  후지  10개  상품  30023.913043  30173.91304347826    -   \n",
      "3   2024-08-07  사과  후지  10개  상품  29940.909091  30023.91304347826    -   \n",
      "4   2024-08-08  사과  후지  10개  상품  28869.047619   29940.9090909091    -   \n",
      "5   2024-08-09  사과  후지  10개  상품  29200.000000  28869.04761904761    -   \n",
      "6   2024-08-12  사과  후지  10개  상품  28111.627907                  -    -   \n",
      "7   2024-08-13  사과  후지  10개  상품  28000.000000  28111.62790697674    -   \n",
      "8   2024-08-14  사과  후지  10개  상품  28014.285714              28000    -   \n",
      "9   2024-08-16  사과  후지  10개  상품  30945.833333                  -    -   \n",
      "10  2024-08-19  사과  후지  10개  상품  33189.473684                  -    -   \n",
      "11  2024-08-20  사과  후지  10개  상품  30635.714286  33189.47368421053    -   \n",
      "\n",
      "          조회일자 지역(시)  ... 품목명  총반입량  전일_y  전년_y  서울청과  농협  중앙청과  동화청과  한국청과  \\\n",
      "0   2024-08-02    서울  ...  사과    50    77    62    22   8     7     5     8   \n",
      "1   2024-08-05    서울  ...  사과    83     0     0    18  15    30    11     9   \n",
      "2   2024-08-06    서울  ...  사과    41    83     0     5   7    16    12     2   \n",
      "3   2024-08-07    서울  ...  사과    59    42    83    18  13    17     4     7   \n",
      "4   2024-08-08    서울  ...  사과    50    59    40     6   6    24    10     3   \n",
      "5   2024-08-09    서울  ...  사과    55    49    83    20  13    11     7     4   \n",
      "6   2024-08-12    서울  ...  사과   174     0    42    43  20    87    15     9   \n",
      "7   2024-08-13    서울  ...  사과    81   174     0    32  14    15    15     5   \n",
      "8   2024-08-14    서울  ...  사과   113    81   146    45  19    29    15     6   \n",
      "9   2024-08-16    서울  ...  사과    87   113    84    17  19    27    16     6   \n",
      "10  2024-08-19    서울  ...  사과   140     0    80    38  13    63    15    11   \n",
      "11  2024-08-20    서울  ...  사과   104   140     0    28  17    44    11     5   \n",
      "\n",
      "    대아청과  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n",
      "5      0  \n",
      "6      0  \n",
      "7      0  \n",
      "8      0  \n",
      "9      0  \n",
      "10     0  \n",
      "11     0  \n",
      "\n",
      "[12 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "# join 으로 합치기\n",
    "import pandas as pd\n",
    "\n",
    "# 각 CSV 파일 읽기\n",
    "df_weather = pd.read_csv('test/기후데이터 20240802-20240820_UTF8_날짜형식변환.csv')  # 기후 데이터 (조회일자)\n",
    "df_sales = pd.read_csv('test/사과후지 소매가격 20240802-20240820.csv')    # 판매 데이터 (판매날짜)\n",
    "df_import = pd.read_csv('test/가락시장 반입량 20240802-20240820.csv')    # 반입 데이터 (반입날짜)\n",
    "\n",
    "# 1단계: 판매날짜와 조회일자 병합 (판매날짜 기준)\n",
    "df_merged_sales_weather = pd.merge(df_sales, df_weather, left_on='DATE', right_on='조회일자', how='left')\n",
    "\n",
    "# 2단계: 병합된 데이터와 반입날짜 병합 (판매날짜 기준)\n",
    "final_df = pd.merge(df_merged_sales_weather, df_import, left_on='DATE', right_on='DATE', how='left')\n",
    "\n",
    "# 결과 확인\n",
    "print(final_df)\n",
    "\n",
    "# 최종 결과를 CSV 파일로 저장\n",
    "final_df.to_csv('test/test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a27b903e-06e9-4aa4-b2b9-0f7650ef5d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DATE', '품목', '품종', '거래단위', '등급', '평균가격', '전일_x', '전년_x', '조회일자',\n",
      "       '지역(시)', '지역(군)', '평균 기온(°C)', '최고 기온(°C)', '최저 기온(°C)', '전년 기온(°C)',\n",
      "       '평년 기온(°C)', '평균 강수량(mm)', '전년 강수량(mm)', '평년 강수량(mm)', '평균 일조시간(hr)',\n",
      "       '전년 일조시간(hr)', '평년 일조시간(hr)', '평균 일사량(MJ/㎡)', '전년 일사량(MJ/㎡)',\n",
      "       '평년 일사량(MJ/㎡)', '평균 습도(%)', '전년 습도(%)', '평년 습도(%)', '평균 운량(1/10)',\n",
      "       '전년 운량(1/10)', '평년 운량(1/10)', '평균 적설량(cm)', '전년 적설량(cm)', '평년 적설량(cm)',\n",
      "       '평균 순간최대풍속(m/s)', '전년 순간최대풍속(m/s)', '평년 순간최대풍속(m/s)', '품목명', '총반입량',\n",
      "       '전일_y', '전년_y', '서울청과', '농협', '중앙청과', '동화청과', '한국청과', '대아청과'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 합친 데이터 불러오기\n",
    "\n",
    "df = pd.read_csv('test/test_data.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8335ee1d-5bd4-4cb9-8637-51d97505d117",
   "metadata": {},
   "source": [
    "# 1차 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "170e177d-4a90-4d5e-8e91-6fedc40b9341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DATE', '품목', '품종', '거래단위', '등급', '평균가격', '전일_x', '조회일자', '지역(시)',\n",
      "       '지역(군)', '평균 기온(°C)', '최고 기온(°C)', '최저 기온(°C)', '평균 강수량(mm)',\n",
      "       '평균 일조시간(hr)', '평균 습도(%)', '평균 적설량(cm)', '평균 순간최대풍속(m/s)', '품목명',\n",
      "       '총반입량', '전일_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 칼럼 삭제\n",
    "df = df.drop(['전년_x','전년 기온(°C)','평년 기온(°C)', '전년 강수량(mm)', '평년 강수량(mm)', \n",
    "        '전년 일조시간(hr)', '평년 일조시간(hr)', '평균 일사량(MJ/㎡)', '전년 일사량(MJ/㎡)',\n",
    "        '평년 일사량(MJ/㎡)', '전년 습도(%)', '평년 습도(%)', '평균 운량(1/10)','전년 운량(1/10)',\n",
    "        '평년 운량(1/10)',  '전년 적설량(cm)', '평년 적설량(cm)','전년 순간최대풍속(m/s)',\n",
    "        '평년 순간최대풍속(m/s)','전년_y', '서울청과', '농협', '중앙청과', '동화청과', '한국청과', '대아청과'], axis=1)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c31a3483-d455-4db5-b07c-83a5698e1192",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          DATE  품목  품종 거래단위  등급          평균가격               전일_x        조회일자  \\\n",
      "0   2024-08-02  사과  후지  10개  상품  30535.416667  30133.33333333333  2024-08-02   \n",
      "1   2024-08-05  사과  후지  10개  상품  30173.913043                  -  2024-08-05   \n",
      "2   2024-08-06  사과  후지  10개  상품  30023.913043  30173.91304347826  2024-08-06   \n",
      "3   2024-08-07  사과  후지  10개  상품  29940.909091  30023.91304347826  2024-08-07   \n",
      "4   2024-08-08  사과  후지  10개  상품  28869.047619   29940.9090909091  2024-08-08   \n",
      "5   2024-08-09  사과  후지  10개  상품  29200.000000  28869.04761904761  2024-08-09   \n",
      "6   2024-08-12  사과  후지  10개  상품  28111.627907                  -  2024-08-12   \n",
      "7   2024-08-13  사과  후지  10개  상품  28000.000000  28111.62790697674  2024-08-13   \n",
      "8   2024-08-14  사과  후지  10개  상품  28014.285714              28000  2024-08-14   \n",
      "9   2024-08-16  사과  후지  10개  상품  30945.833333                  -  2024-08-16   \n",
      "10  2024-08-19  사과  후지  10개  상품  33189.473684                  -  2024-08-19   \n",
      "11  2024-08-20  사과  후지  10개  상품  30635.714286  33189.47368421053  2024-08-20   \n",
      "\n",
      "   지역(시) 지역(군)  ...  최고 기온(°C)  최저 기온(°C)  평균 강수량(mm)  평균 일조시간(hr)  평균 습도(%)  \\\n",
      "0     서울   종로구  ...       32.5       28.2         0.0          2.4      79.4   \n",
      "1     서울   종로구  ...       33.7       26.9         1.3          3.4      75.5   \n",
      "2     서울   종로구  ...       33.5       25.6         0.0          6.2      74.8   \n",
      "3     서울   종로구  ...       33.4       27.2         3.4          7.6      72.0   \n",
      "4     서울   종로구  ...       31.6       26.9         0.0          2.4      77.5   \n",
      "5     서울   종로구  ...       33.6       25.6         0.0          6.0      74.1   \n",
      "6     서울   종로구  ...       34.1       28.2         0.0          4.1      70.5   \n",
      "7     서울   종로구  ...       36.4       28.1         0.0          7.5      70.0   \n",
      "8     서울   종로구  ...       34.9       27.3         3.0          4.7      73.0   \n",
      "9     서울   종로구  ...       34.3       26.8         0.0          6.7      69.4   \n",
      "10    서울   종로구  ...       35.3       26.3         2.3          7.1      72.3   \n",
      "11    서울   종로구  ...       35.4       27.0         0.0          7.7      68.3   \n",
      "\n",
      "    평균 적설량(cm)  평균 순간최대풍속(m/s)  품목명   총반입량   전일_y  \n",
      "0          0.0             7.1   사과   50.0   77.0  \n",
      "1          0.0             7.5   사과   83.0    0.0  \n",
      "2          0.0             7.3   사과   41.0   83.0  \n",
      "3          0.0             6.1   사과   59.0   42.0  \n",
      "4          0.0             5.9   사과    NaN   59.0  \n",
      "5          0.0             5.7   사과   55.0   49.0  \n",
      "6          0.0             6.4   사과  174.0    NaN  \n",
      "7          0.0             7.9   사과   81.0  174.0  \n",
      "8          0.0            11.9   사과  113.0   81.0  \n",
      "9          0.0             7.6   사과   87.0  113.0  \n",
      "10         0.0            10.5   사과  140.0    NaN  \n",
      "11         0.0             8.2   사과  104.0  140.0  \n",
      "\n",
      "[12 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# 특정 칼럼 내 중복값 제거\n",
    "df['총반입량'] = df['총반입량'].where(~df.duplicated(subset=['총반입량']), np.nan)\n",
    "df['전일_y'] = df['전일_y'].where(~df.duplicated(subset=['전일_y']), np.nan)\n",
    "\n",
    "# DATE 칼럼을 datetime 형식으로 변환\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "# 요일을 계산하여 '요일' 칼럼에 추가\n",
    "df['요일'] = df['DATE'].dt.day_name()\n",
    "\n",
    "# 요일을 한글로 변경 (예: 'Monday' -> '월요일')\n",
    "def convert_to_korean_day(day_name):\n",
    "    days = {\n",
    "        'Monday': '월요일',\n",
    "        'Tuesday': '화요일',\n",
    "        'Wednesday': '수요일',\n",
    "        'Thursday': '목요일',\n",
    "        'Friday': '금요일',\n",
    "        'Saturday': '토요일',\n",
    "        'Sunday': '일요일'\n",
    "    }\n",
    "    return days.get(day_name, day_name)\n",
    "\n",
    "df['요일'] = df['요일'].apply(convert_to_korean_day)\n",
    "\n",
    "index_of_day = df.columns.get_loc('요일')\n",
    "\n",
    "# '요일' 칼럼을 제외한 나머지 칼럼들\n",
    "other_columns = [col for col in df.columns if col != '요일']\n",
    "\n",
    "# 새로운 칼럼 순서 생성: '요일'을 두 번째로 위치시킵니다.\n",
    "new_order = [other_columns[0]] + ['요일'] + other_columns[1:]\n",
    "\n",
    "# 데이터프레임의 칼럼 순서 재정렬\n",
    "df = df[new_order]\n",
    "\n",
    "# 결측치 처리\n",
    "df = df.fillna(0)\n",
    "df.replace('-', 0, inplace=True)\n",
    "\n",
    "# 타입 변경\n",
    "df['평균가격'] = df['평균가격'].astype(int)\n",
    "df['전일_x'] = pd.to_numeric(df['전일_x'], errors='coerce')\n",
    "df['전일_x'] = df['전일_x'].apply(np.floor).astype('Int64')\n",
    "\n",
    "df.to_csv('test/test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75115fdb-f9ca-4342-a8d7-31db5685bb16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
